{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName('bakery').getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.fpm import FPGrowth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+---+\n",
      "|_c0|_c1|_c2|\n",
      "+---+---+---+\n",
      "|  1|  1| 21|\n",
      "|  1|  5| 11|\n",
      "|  2|  1|  7|\n",
      "|  2|  3| 11|\n",
      "|  2|  4| 37|\n",
      "+---+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.csv('75000i.csv', header= False, inferSchema=True)\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+---+\n",
      "|_c0|_c2|\n",
      "+---+---+\n",
      "|  1| 21|\n",
      "|  1| 11|\n",
      "|  2|  7|\n",
      "|  2| 11|\n",
      "|  2| 37|\n",
      "+---+---+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df = df.drop(*['_c1'])\n",
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------+\n",
      "|order_id|product_id|\n",
      "+--------+----------+\n",
      "|       1|        21|\n",
      "|       1|        11|\n",
      "|       2|         7|\n",
      "|       2|        11|\n",
      "|       2|        37|\n",
      "+--------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    " from pyspark.sql.functions import col\n",
    " df = df.select(col(\"_c0\").alias(\"order_id\"), col(\"_c2\").alias(\"product_id\"))\n",
    " df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import collect_list, col, count, collect_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.createOrReplaceTempView('order_product')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "products = spark.sql('select distinct product_id from order_product')\n",
    "products.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----------------------+\n",
      "|order_id|items                 |\n",
      "+--------+----------------------+\n",
      "|148     |[33, 27, 9, 46, 28, 4]|\n",
      "|463     |[17, 14]              |\n",
      "|471     |[9, 37, 34, 20]       |\n",
      "|496     |[15, 6, 47, 26]       |\n",
      "|833     |[12, 5, 21]           |\n",
      "+--------+----------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rawData = spark.sql('select * from order_product')\n",
    "baskets = rawData.groupBy('order_id').agg(collect_set('product_id').alias('items'))\n",
    "baskets.createOrReplaceTempView('baskets')\n",
    "baskets.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpGrowth = FPGrowth(itemsCol='items', minSupport=0.003, minConfidence=0.003)\n",
    "model = fpGrowth.fit(baskets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+----+\n",
      "|   items|freq|\n",
      "+--------+----+\n",
      "|     [7]|8193|\n",
      "|    [45]|7700|\n",
      "| [45, 7]|2367|\n",
      "|    [28]|7556|\n",
      "|[28, 45]| 387|\n",
      "| [28, 7]| 383|\n",
      "|    [18]|6987|\n",
      "|[18, 28]| 393|\n",
      "|[18, 45]| 318|\n",
      "| [18, 7]| 321|\n",
      "|     [4]|6948|\n",
      "| [4, 28]| 465|\n",
      "| [4, 45]| 372|\n",
      "| [4, 18]| 402|\n",
      "|  [4, 7]| 378|\n",
      "|    [35]|6943|\n",
      "|[35, 28]| 381|\n",
      "| [35, 4]| 388|\n",
      "|[35, 45]| 309|\n",
      "|[35, 18]|3982|\n",
      "+--------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model.freqItemsets.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|order_id|               items|          prediction|\n",
      "+--------+--------------------+--------------------+\n",
      "|     148|[33, 27, 9, 46, 2...|[35, 22, 45, 18, ...|\n",
      "|     463|            [17, 14]|[27, 28, 35, 4, 2...|\n",
      "|     471|     [9, 37, 34, 20]|[19, 33, 27, 17, ...|\n",
      "|     496|     [15, 6, 47, 26]|[27, 33, 1, 28, 3...|\n",
      "|     833|         [12, 5, 21]|[19, 33, 27, 17, ...|\n",
      "|    1088| [27, 35, 3, 18, 40]|[28, 4, 22, 45, 4...|\n",
      "|    1238|        [19, 32, 18]|[28, 45, 7, 4, 35...|\n",
      "|    1342|         [49, 17, 8]|[19, 27, 33, 1, 2...|\n",
      "|    1580|        [12, 31, 36]|[48, 19, 33, 27, ...|\n",
      "|    1591|             [1, 19]|[27, 33, 28, 37, ...|\n",
      "|    1645|         [15, 49, 7]|[27, 33, 1, 28, 3...|\n",
      "|    1829|[15, 49, 38, 6, 7...|[27, 33, 1, 28, 3...|\n",
      "|    1959|[9, 1, 18, 4, 22,...|[28, 45, 7, 35, 4...|\n",
      "|    2122|             [5, 22]|[27, 1, 28, 35, 1...|\n",
      "|    2142|        [14, 44, 41]|[27, 28, 35, 4, 2...|\n",
      "|    2366|         [0, 27, 29]|[28, 35, 4, 22, 4...|\n",
      "|    2659|                [42]|[28, 35, 4, 45, 1...|\n",
      "|    2866|         [2, 28, 40]|[45, 7, 18, 4, 35...|\n",
      "|    3175|            [33, 42]|[28, 35, 4, 45, 1...|\n",
      "|    3749|         [45, 4, 11]|[28, 18, 7, 35, 4...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_id = model.transform(baskets)\n",
    "predict_id.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+------------+------+-----+------+\n",
      "|Id |Flavor      |Food  |Price|Type  |\n",
      "+---+------------+------+-----+------+\n",
      "|0  |'Chocolate' |'Cake'|8.95 |'Food'|\n",
      "|1  |'Lemon'     |'Cake'|8.95 |'Food'|\n",
      "|2  |'Casino'    |'Cake'|15.95|'Food'|\n",
      "|3  |'Opera'     |'Cake'|15.95|'Food'|\n",
      "|4  |'Strawberry'|'Cake'|11.95|'Food'|\n",
      "+---+------------+------+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_data = spark.read.csv('goods.csv', header=True, inferSchema=True)\n",
    "product_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Id: integer (nullable = true)\n",
      " |-- Flavor: string (nullable = true)\n",
      " |-- Food: string (nullable = true)\n",
      " |-- Price: double (nullable = true)\n",
      " |-- Type: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "product_data.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----+-----+------+\n",
      "|Id |Flavor    |Food|Price|Type  |\n",
      "+---+----------+----+-----+------+\n",
      "|0  |Chocolate |Cake|8.95 |'Food'|\n",
      "|1  |Lemon     |Cake|8.95 |'Food'|\n",
      "|2  |Casino    |Cake|15.95|'Food'|\n",
      "|3  |Opera     |Cake|15.95|'Food'|\n",
      "|4  |Strawberry|Cake|11.95|'Food'|\n",
      "+---+----------+----+-----+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pyspark.sql.functions as f\n",
    "product_data = product_data.withColumn(\"Flavor\", f.split(product_data['Flavor'], \"\\'\")[1])\n",
    "product_data = product_data.withColumn(\"Food\", f.split(product_data['Food'], \"\\'\")[1])\n",
    "product_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+----+-----+------+---------------+\n",
      "|Id |Flavor    |Food|Price|Type  |product_name   |\n",
      "+---+----------+----+-----+------+---------------+\n",
      "|0  |Chocolate |Cake|8.95 |'Food'|Chocolate Cake |\n",
      "|1  |Lemon     |Cake|8.95 |'Food'|Lemon Cake     |\n",
      "|2  |Casino    |Cake|15.95|'Food'|Casino Cake    |\n",
      "|3  |Opera     |Cake|15.95|'Food'|Opera Cake     |\n",
      "|4  |Strawberry|Cake|11.95|'Food'|Strawberry Cake|\n",
      "+---+----------+----+-----+------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql.functions import concat_ws\n",
    "product_data = product_data.withColumn('product_name', concat_ws(\" \",product_data.Flavor,product_data.Food))\n",
    "product_data.show(5, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "product_data.createOrReplaceTempView('products')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rawData1 = spark.sql('select p.product_name, o.order_id from products p inner join order_product o where o.product_id = p.Id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(order_id=148, items=['Tuile Cookie', 'Strawberry Cake', 'Napoleon Cake', 'Chocolate Coffee', 'Cheese Croissant', 'Marzipan Cookie']),\n",
       " Row(order_id=463, items=['Berry Tart', 'Chocolate Tart']),\n",
       " Row(order_id=471, items=['Almond Twist', 'Chocolate Croissant', 'Pecan Tart', 'Napoleon Cake'])]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baskets1 = rawData1.groupBy('order_id').agg(collect_set('product_name').alias('items'))\n",
    "baskets1.createOrReplaceTempView('baskets')\n",
    "baskets1.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "fpGrowth1 = FPGrowth(itemsCol='items', minSupport=0.003, minConfidence=0.003)\n",
    "model1 = fpGrowth1.fit(baskets1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---------------------------------+----+\n",
      "|items                            |freq|\n",
      "+---------------------------------+----+\n",
      "|[Coffee Eclair]                  |8193|\n",
      "|[Hot Coffee]                     |7700|\n",
      "|[Hot Coffee, Coffee Eclair]      |2367|\n",
      "|[Tuile Cookie]                   |7556|\n",
      "|[Tuile Cookie, Hot Coffee]       |387 |\n",
      "|[Tuile Cookie, Coffee Eclair]    |383 |\n",
      "|[Cherry Tart]                    |6987|\n",
      "|[Cherry Tart, Tuile Cookie]      |393 |\n",
      "|[Cherry Tart, Hot Coffee]        |318 |\n",
      "|[Cherry Tart, Coffee Eclair]     |321 |\n",
      "|[Strawberry Cake]                |6948|\n",
      "|[Strawberry Cake, Tuile Cookie]  |465 |\n",
      "|[Strawberry Cake, Hot Coffee]    |372 |\n",
      "|[Strawberry Cake, Cherry Tart]   |402 |\n",
      "|[Strawberry Cake, Coffee Eclair] |378 |\n",
      "|[Apricot Danish]                 |6943|\n",
      "|[Apricot Danish, Tuile Cookie]   |381 |\n",
      "|[Apricot Danish, Strawberry Cake]|388 |\n",
      "|[Apricot Danish, Hot Coffee]     |309 |\n",
      "|[Apricot Danish, Cherry Tart]    |3982|\n",
      "+---------------------------------+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model1.freqItemsets.show(truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+--------------------+--------------------+\n",
      "|order_id|               items|          prediction|\n",
      "+--------+--------------------+--------------------+\n",
      "|     148|[Tuile Cookie, St...|[Hot Coffee, Cher...|\n",
      "|     463|[Berry Tart, Choc...|[Lemon Tart, Marz...|\n",
      "|     471|[Almond Twist, Ch...|[Marzipan Cookie,...|\n",
      "|     496|[Vanilla Meringue...|[Lemon Tart, Marz...|\n",
      "|     833|[Ganache Cookie, ...|[Lemon Tart, Chee...|\n",
      "|    1088|[Cherry Tart, Ope...|[Cheese Croissant...|\n",
      "|    1238|[Cherry Tart, Apr...|[Marzipan Cookie,...|\n",
      "|    1342|[Single Espresso,...|[Lemon Tart, Marz...|\n",
      "|    1580|[Apple Croissant,...|[Lemon Tart, Chee...|\n",
      "|    1591|[Lemon Cake, Lemo...|[Marzipan Cookie,...|\n",
      "|    1645|[Coffee Eclair, B...|[Hot Coffee, Tuil...|\n",
      "|    1829|[Coffee Eclair, A...|[Lemon Tart, Rasp...|\n",
      "|    1959|[Cherry Tart, Lem...|[Tuile Cookie, Ho...|\n",
      "|    2122|[Truffle Cake, Go...|[Tuile Cookie, Ap...|\n",
      "|    2142|[Bottled Water, B...|[Lemon Tart, Chee...|\n",
      "|    2366|[Walnut Cookie, C...|[Tuile Cookie, Ap...|\n",
      "|    2659|      [Orange Juice]|[Tuile Cookie, Ap...|\n",
      "|    2866|[Tuile Cookie, Ca...|[Hot Coffee, Coff...|\n",
      "|    3175|[Orange Juice, Ch...|[Tuile Cookie, Ap...|\n",
      "|    3749|[Strawberry Cake,...|[Tuile Cookie, Ch...|\n",
      "+--------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict_id1 = model1.transform(baskets1)\n",
    "predict_id1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
